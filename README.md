# Image and Video Prediction API

This is a robust, production-ready REST API built with FastAPI and powered by YOLO models. It provides a complete solution for uploading images and videos, performing machine learning predictions (classification for images, object detection for videos), and serving the labeled results.

The entire service is containerized with Docker and managed via Docker Compose, ensuring a reproducible and scalable environment.

---

## Core Features

- **File Upload**: Securely upload images (`.jpg`, `.png`) and videos (`.mp4`).
- **Machine Learning Predictions**:
  - **Image Classification**: Uses a YOLO classification model to identify the contents of an image.
  - **Video Object Detection**: Uses a YOLO object detection model to find and track objects frame-by-frame.
- **Dynamic Labeling**: Automatically generates new image and video files with predictions (class names, confidence scores, bounding boxes) drawn directly onto them.
- **Static File Serving**: Exposes the labeled media files through a dedicated `/assets` endpoint.
- **Configurable Environment**: All settings, including model paths, server ports, and supported file types, are managed through a `.env` file for easy configuration across different environments (dev, prod).
- **Production-Ready Setup**:
  - **Dockerized**: The entire application and its dependencies are containerized.
  - **Multi-Stage Dockerfile**: Creates a small, optimized, and secure final image.
  - **Docker Compose**: Simplifies setup and management of the service and its volumes.
  - **Non-Root User**: Runs the application as a non-root user inside the container for enhanced security.
  - **Named Volumes**: Ensures data (uploads, predictions, models) persists reliably.

---

## API Documentation

The API exposes three main endpoints.

### 1. `POST /upload`

Upload an image or video file to the service. The file is saved and a unique filename is returned, which is then used for prediction.

- **Method**: `POST`
- **Endpoint**: `/upload`
- **Body**: `multipart/form-data` with a single file field.
- **Supported Content-Types**: `image/jpeg`, `image/png`, `video/mp4` (configurable via `.env`).

#### Example Request (`curl`)

```bash
curl -X POST "[http://127.0.0.1:8000/upload](http://127.0.0.1:8000/upload)" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@/path/to/your/image.jpg"

Example Success Response (201 Created)

{
  "filename": "a1b2c3d4e5_1678886400.jpg"
}

2. GET /predict/{filename}

Perform a prediction on a previously uploaded file. The service automatically uses the correct model (classification for images, detection for videos) based on the file extension.

    Method: GET

    Endpoint: /predict/{filename}

    Path Parameter:

        filename (string, required): The unique filename returned by the /upload endpoint.

    Query Parameters:

        conf (float, optional, default: 0.25): Confidence threshold for object detection in videos.

        imgsz (int, optional, default: 640): Image size for model input.

        speed_factor (float, optional, default: 2.0): Playback speed modifier for output videos. >1 is slower, <1 is faster.

Example Request (curl)

For an image:

curl -X GET "[http://127.0.0.1:8000/predict/a1b2c3d4e5_1678886400.jpg?imgsz=1280](http://127.0.0.1:8000/predict/a1b2c3d4e5_1678886400.jpg?imgsz=1280)"

For a video (slowing it down to quarter speed):

curl -X GET "[http://127.0.0.1:8000/predict/f6g7h8i9j0_1678886500.mp4?conf=0.4&speed_factor=4.0](http://127.0.0.1:8000/predict/f6g7h8i9j0_1678886500.mp4?conf=0.4&speed_factor=4.0)"

Example Success Response (200 OK)

For an image:

{
    "filename": "a1b2c3d4e5_1678886400.jpg",
    "parameters": {
        "conf": 0.25,
        "imgsz": 1280,
        "speed_factor": 2.0
    },
    "results": {
        "predictions": [
            {"class_name": "cat", "confidence": 0.94},
            {"class_name": "dog", "confidence": 0.05},
            {"class_name": "couch", "confidence": 0.01}
        ],
        "path": "/assets/predictions/a1b2c3d4e5_1678886400_predicted.jpg",
        "model": "YOLO Classifier"
    }
}

For a video:

{
    "filename": "f6g7h8i9j0_1678886500.mp4",
    "parameters": {
        "conf": 0.4,
        "imgsz": 640,
        "speed_factor": 4.0
    },
    "results": {
        "detections": [
            [{"class_name": "person", "confidence": 0.88}],
            [{"class_name": "person", "confidence": 0.89}, {"class_name": "car", "confidence": 0.76}]
        ],
        "path": "/assets/predictions/f6g7h8i9j0_1678886500_predicted.mp4",
        "model": "YOLOv8 Detection"
    }
}

3. GET /assets/{filename}

Serve a static file (image or video) from the assets directory. This is used to retrieve the labeled media generated by the /predict endpoint.

    Method: GET

    Endpoint: /assets/{filename}

Example Request (In Browser or curl)

# To view the labeled image from the example above
[http://127.0.0.1:8000/assets/a1b2c3d4e5_1678886400_predicted.jpg](http://127.0.0.1:8000/assets/a1b2c3d4e5_1678886400_predicted.jpg)

# To view the labeled video
[http://127.0.0.1:8000/assets/f6g7h8i9j0_1678886500_predicted.mp4](http://127.0.0.1:8000/assets/f6g7h8i9j0_1678886500_predicted.mp4)

Setup and Running

This project is designed to be run with Docker and Docker Compose.
Prerequisites

    Docker

    Docker Compose

1. Project Structure

Ensure your project is structured as follows:

.
├── app/
│   ├── __init__.py
│   ├── config.py
│   └── main.py
├── assets/
│   └── models/
│       ├── <classifier>.pt
│       └── <detection>.pt
├── builds/
│   ├── Dockerfile
│   └── entrypoint.sh
├── .env
├── .env.example
├── compose.yaml
└── requirements.txt

2. Configuration

Copy the example environment file to create your local configuration:

cp example.env .env

You can now edit the .env file to change the server port, model paths, or supported file types. The default values will work out-of-the-box.
3. Add Your Models

Place your trained YOLO models into the assets/models/ directory. Ensure they are named cnn.pt (for classification) and detect.pt (for detection), or update the paths in your .env file.
4. Build and Run the Service

From the root directory of the project, run the following command:

docker-compose -f compose.yaml up --build

    --build: This flag is only needed the first time you run the service or after making changes to the Dockerfile, entrypoint.sh, or requirements.txt.

    For subsequent runs, you can simply use docker-compose -f compose.yaml up.

The API will be available at http://127.0.0.1:8000 (or whichever port you configured in .env).
5. Stop the Service

To stop the running containers, press Ctrl+C in the terminal where compose is running, and then execute:

docker-compose -f compose.yaml down


```
